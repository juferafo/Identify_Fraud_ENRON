{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: Identify Fraud from ENRON Email\n",
    "\n",
    "\n",
    "The ENRON case was one of the most important financial scandals in the history of EEUU. The corporation emerged in 1985 as a result of Houston Natural Gas and InterNorth fusion. After the legislation of energy deregulation laws, ENRON started to build a complex financial business model. This, together with unethical methods such as false accounting records to hide failed investments were the key to obtain revenues of nearly 101\\$ billion during the year 2000. ENRON was the biggest company at that time employing more than 21000 people with investments all over 40 countries. In summer of 2000, the price per action reached the peak value around 90\\$, one year and a half later the company declared bankruptcy.  \n",
    "\n",
    "The goal of this project is to identify persons of interest (POI) among the employees of ENRON. We will consider POI as any individual who was responsible for any financial irregularity that led to the corporation's insolvency. To do so, we are provided with a dataset which contains financial and email-related data such as salary, long-term bonus, stock information and POI status. We will apply machine-learning techniques to train a predictive model able classify employees into POIs/non POIs.\n",
    "\n",
    "This report is organized as follows: in Section I we provide a description of the dataset and the procedures employed to identify and remove outliers. Feature selection and different machine learning algorithms are explained in Section II where we perform a comparison between different classifiers based on statistical metrics such as average score, recall or precision. Parameter tuning is performed over the best model found to improve its efficiency. Finally, we conclude and provide a list of references used during this work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section I: ENRON dataset\n",
    "\n",
    "#### Dataset description\n",
    "\n",
    "We start the analysis by providing some insight into the ENRON dataset stored in ```./final_project_dataset.pkl```. Since this file contains human-entered data it is necessary to preprocess it to correct possible incomplete or wrong information. After cross-checking the data with published records (```./enron61702insiderpay.pdf```) three errors were observed:\n",
    "\n",
    "* The entries 'TOTAL' and 'THE TRAVEL AGENCY IN THE PARK' do not refer to any individual. In the case of 'TOTAL' we can assume that it is a spread-sheet error produced while exporting the data. As shown in Fig. 2, this point is a clear outlier.\n",
    "\n",
    "* The features of 'BHATNAGAR SANJAY' and 'BELFER ROBERT' were incorrectly filled. The data was corrected and updated with the method ```correct_data``` defined in ```./modules/data_cleaning.py```.\n",
    "\n",
    "* The data of 'LOCKHART EUGENE E' is empty. This point will be automatically removed by the ```featureFormat``` method when transforming the raw data into a matrix.\n",
    "\n",
    "The dataset contains 144 valid entries with 19 features related to financial (such as salary, bonus, total stock value, etc...) and email information (messages to POIs, messages from POIs). POI is the field used to binary-classify the employees. This dataset is strongly unbalanced towards the non-POI class since only 19 out of 144 employees are POIs. This aspect will be important during the data cleaning process and model validation.\n",
    "\n",
    "Completeness of the data is usually a problem while working with real-world data. The bar plot shown in Fig. 1 depicts the number of NaNs per feature. Fields like 'poi',  'restricted stock value' or 'total payments' are the ones with least amount of empty data in contrast with 'loan advances', 'director fees' or 'restricted stock deferred'. The presence of NaN values has a direct effect on the quality of a given feature and will influence which features are relevant to choose during the algorithm training.\n",
    "\n",
    "**Figure 1** ![EDA_plot](./figures/features_nans.pdf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Outliers\n",
    "\n",
    "Outliers identification is essential to distinguish data points that deviate from the general trend an may affect negatively the outcome of the study. A first approach can be done just by exploring the relationship between different features. Fig. 2 shows the dependence between bonus, salary, exercised_stock_options and total_stock_value with and without outliers.\n",
    "\n",
    "**Figure 2** ![EDA_plot](./figures/plot_EDA.pdf)\n",
    "\n",
    "There is one clear outlier in the left panels which corresponds to the 'TOTAL' point. After the outlier is removed we see that the plot dimensions are reduced to ranges that agree with the employee's data. The outlier removal can be increased upon consideration of a linear dependence between the plotted features. In Fig. 3 we show that, after removing the biggest deviated data (10%), the $R^2$ coefficient increases as expected. However, this is not a good approach while working with strongly imbalanced data. Taking a closer look to the outliers (blue points in Fig. 3) one can detect that some of them are POIs like Kenneth Lay. Removing these points would not improve the quality of the model. The outliers and POI status detected in Fig. 3 are displayed in Table 1.\n",
    "\n",
    "**Figure 3** ![EDA_plot](./figures/outlier_removal_regression.pdf)\n",
    "\n",
    "**Table 1**\n",
    "\n",
    "| salary  vs.  bonus | POI status |   | total stock value  vs.  exercised stock options | POI status |\n",
    "|:------------------:|:----------:|:-:|:-----------------------------------------------:|:----------:|\n",
    "|   KITCHEN LOUISE   |    False   |   |                  LAY KENNETH L                  |    True    |\n",
    "|   LAVORATO JOHN J  |    False   |   |                  RICE KENNETH D                 |    True    |\n",
    "|  DELAINEY DAVID W  |    True    |   |                  KEAN STEVEN J                  |    False   |\n",
    "|    LAY KENNETH L   |    True    |   |                WHITE JR THOMAS E                |    False   |\n",
    "|  BELDEN TIMOTHY N  |    True    |   |               DIMICHELE RICHARD G               |    False   |\n",
    "|  PICKERING MARK R  |    False   |   |                 BHATNAGAR SANJAY                |    False   |\n",
    "|   ALLEN PHILLIP K  |    False   |   |                   HIRKO JOSEPH                  |    True    |\n",
    "|   FREVERT MARK A   |    False   |   |               DERRICK JR. JAMES V               |    False   |\n",
    "|                    |            |   |                     PAI LOU                     |    False   |\n",
    "|                    |            |   |                 IZZO LAWRENCE L                 |    False   |\n",
    "\n",
    "The outlier identification was performed combining the methods ```plot_EDA```, ```outliers_regression```, ```outliers_regression_plot``` and ```outliers_identification``` defined in ```./modules/ML_methods.py```.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2: Machine learning algorithm\n",
    "\n",
    "During this section, we are going to discuss the structure of the machine learning code and the steps employed to build the model. The general basic structure of a machine learning algorithm consists on three parts: first the data is split into train and test sets, the algorithm of our choice (Naive Bayes, SVM, Decision Tree...) is fitted using the training data and, finally, validated with the test set. To increase the efficiency of our model, we are going to add a few extra steps like feature selection and parameter tuning.\n",
    "\n",
    "#### Feature selection\n",
    "\n",
    "Once the data is cleaned of NaNs and outliers, it is important to select the relevant number of features to be considered in the classification. This is one way to tune the bias-variance tradeoff. A simple model with a small number of features (bias) will have a low performance in both train and test data and, on the other hand, a complex one (variance) will describe better the particularities of the training set but will not be accurate enough in the test part. The k-best number of features were selected employing the ```get_kbest_features``` definition coded in ```./modules/ML_methods.py```. As shown in Table 3, the ```SelectKBest``` methods provide a coefficient related to the importance of the feature. 'total_stock_value', 'exercised_stock_values', 'bonus' and 'salary' are the most relevant features in the dataset. From them, the new fields were built with the intention to provide new information to classify the employees. 'salary_bonus' ('total_value') was calculated by adding up 'salary', 'bonus' and 'total_stock_value' ('salary' and 'bonus'). In the following table, we show a comparison of the 10 best features with and without the 'salary_bonus' and 'total_value' fields.\n",
    "\n",
    "**Table 3**\n",
    "<table>\n",
    "<tr><th>Default features</th><th></th><th>Features 'salary_bonus' and 'total_value' included</th><th></th></tr>  \n",
    "<tr><th>Features</th><th>Score</th><th>Features</th><th>Score</th></tr>\n",
    "<tr><td>total_stock_value</td><td>22.511</td><td>total_stock_value</td><td>22.511</td></tr>\n",
    "<tr><td>exercised_stock_options</td><td>22.349</td><td>salary_bonus</td><td>22.456</td></tr>\n",
    "<tr><td>bonus</td><td>20.792</td><td>exercised_stock_options</td><td>22.349</td></tr>\n",
    "<tr><td>salary</td><td>18.29</td><td>bonus</td><td>20.792</td></tr>\n",
    "<tr><td>deferred_income</td><td>11.425</td><td>total_value</td><td>19.225</td></tr>\n",
    "<tr><td>long_term_incentive</td><td>9.922</td><td>salary</td><td>18.29</td></tr>\n",
    "<tr><td>total_payments</td><td>9.284</td><td>deferred_income</td><td>11.425</td></tr>\n",
    "<tr><td>restricted_stock</td><td>8.825</td><td>long_term_incentive</td><td>9.922</td></tr>\n",
    "<tr><td>shared_receipt_with_poi</td><td>8.589</td><td>total_payments</td><td>9.284</td></tr>\n",
    "<tr><td>loan_advances</td><td>7.184</td><td>restricted_stock</td><td>8.825</td></tr>\n",
    "</table> \n",
    "\n",
    "The new features were coded with the ```create_salarybonus_feature``` and ```create_value_feature``` methods defined in ```./modules/data_cleaning.py``` \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification algorithm\n",
    "\n",
    "During this project, we have evaluated the performance of different classifiers: Naive Bayes, Decision Tree, Random Forest and Ada Boost. Code 1 block shows an example of the classification's code using the Naive Bayes model. The steps taken during the classification are the same for all the classifiers tested. First, the dataset to the 10 best features as found in the previous subsection (Table 3 right). After that, we build and generalize the model using *k*-fold cross-validation (CV) implemented with ```perform_classification``` method defined in ```./modules/ML_methods.py```.\n",
    "\n",
    "This method is especially useful to treat class-disproportionated data. Instead of performing a train-test split once, the *k*-fold CV divides the data into *k* sets called folds. The classification is built using *k-1* folds and evaluated with the remaining one. This process is repeated k times for all the folds. The effectiveness of the model is computed from the mean value of different statistical metrics obtained for all the folds. CV is broadly used to improve the model generalization. In the following table, we display the accuracy score (ratio between the predicted and real test values) for different classificators.\n",
    "\n",
    "**Table 4**\n",
    "\n",
    "|Algorithm|Accuracy score|Recall score|Precission score|F1 score|\n",
    "|:------------------:|:----------:|:----------:|:----------:|\n",
    "|Naive Bayes         |0.8362|0.3035|0.3218|0.2937|\n",
    "|Decission Tree      |0.8073|0.2890|0.2631|0.2573|\n",
    "|Random Forest       |0.8532|0.1605|0.2256|0.1796|\n",
    "|Ada Boost           |0.8463|0.2270|0.2846|0.2392|\n",
    "\n",
    "Accuracy, recall and precission precission are defined as follows:\n",
    "\n",
    "* Accuracy $ \\equiv $ Ratio of data classified correctly\n",
    "* Recall $ \\equiv TP / (TP + FN)$\n",
    "* Precission $ \\equiv TP / (TP + FP)$\n",
    "* F1 $ \\equiv 2 \\cdot (P \\cdot R) / (P + R)$\n",
    "\n",
    "where TP, TN, FP and FN are true positive, true negative, false positive and false negative classified values. \n",
    "\n",
    "In the case of unbalanced data, the accuracy score is not a good metric to evaluate the goodness of the model. Since the majority of the ENRON employees are non-POIs, a model that ignores the POI data would correctly classify the ordinary workers and produce a good accuracy score. One would better consider other metrics such as recall, precision or F1. The recall reflects the amount of correctly classified POIs, or in other words, the modelâ€™s ability to find all the data points of interest in a dataset. The precision, on the other hand, shows how relevant is the POI classified data. By increasing the recall the precision decreases and vice-versa. The tradeoff between these variables can be measured with the F1 score.\n",
    "\n",
    "From the values shown in the table above, we see that the Naive Bayes classifier has the best recall, precision and F1 scores. Therefore, among the tested models, the Naive Bayes classifier is the one which presents the best performance of all."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Code 1: Naive Bayes classification**\n",
    "```python\n",
    "def perform_classification(clf, steps, features, labels, folds = 100):\n",
    "    '''\n",
    "    This method performs the cross validation using the provided clf classifier.\n",
    "    It builds a Pipeline with the selected steps. \n",
    "    It returns both the estimator and a dictionary containing \n",
    "    the mean value of the accuracy, precission, recall and f1 scores.\n",
    "    '''\n",
    "    \n",
    "    # Cross-validation method\n",
    "    cv_kfold = StratifiedShuffleSplit(labels, folds, random_state = 42)\n",
    "    pipe  = Pipeline(steps)\n",
    "    \n",
    "    # Metric scores to be computed\n",
    "    scoring = {'accuracy'  : make_scorer(accuracy_score),\n",
    "               'precision' : make_scorer(precision_score),\n",
    "               'recall'    : make_scorer(recall_score),\n",
    "               'f1_score'  : make_scorer(f1_score)}\n",
    "\n",
    "    results = cross_validate(estimator = pipe,\\\n",
    "                             X = features,\\\n",
    "                             y = labels,\\\n",
    "                             cv = cv_kfold,\\\n",
    "                             scoring = scoring)\n",
    "    \n",
    "    for key in results.keys():\n",
    "        results[key] = np.mean(results[key])\n",
    "\n",
    "    return pipe, results\n",
    "\n",
    "\n",
    "print \"Performing Naive Bayes classification\\n\"\n",
    "# Classifier declaration\n",
    "clf_NB   = GaussianNB()\n",
    "# Algorithm steps: 1) Feature selection, 2) Model construction\n",
    "steps_NB = [('feature_selection', feature_selection), ('Naive_Bayes', clf_NB)]\n",
    "pipe_NB, results_NB = perform_classification(clf_NB, steps_NB, features, labels)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameter tuning\n",
    "\n",
    "We have performed parameter tuning on the Naive Bayes algorithm to find the set of parameters that improve the POI identification. In this case, we can only tune the number of features selected during the fit. As shown in the Code 2 block, this process is implemented with the ```GridSearchCV``` method. The best score parameters were found for the Naive Bayes classifier considering 12 features. The following table we show the score metrics before and after the parameter tuning.\n",
    "\n",
    "**Table 5**\n",
    "\n",
    "|Algorithm|Accuracy score|Recall score|Precission score|F1 score|\n",
    "|:------------------:|:----------:|:----------:|:----------:|\n",
    "|Naive Bayes default |0.8467|0.3800|0.4052|0.3649|\n",
    "|Naive Bayes tuned   |0.8452|0.3280|0.4014|0.3610|\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Code 2: Parameter tuning method**\n",
    "```python\n",
    "def grid_search(steps, clf_parameters, features, labels, folds = 100):\n",
    "    '''\n",
    "    This method performs a cross validation parameter tuning.\n",
    "    To do so, it builds a Pipeline and employes GridSearchCV over the provided\n",
    "    range of parameters.\n",
    "    '''\n",
    "\n",
    "    pipe    = Pipeline(steps)\n",
    "    cv_kfold = StratifiedShuffleSplit(labels, folds, random_state = 42)\n",
    "    cv_grid = GridSearchCV(pipe, param_grid = clf_parameters, cv = cv_kfold)\n",
    "    cv_grid.fit(features, labels)\n",
    "\n",
    "    return cv_grid\n",
    "\n",
    "\n",
    "print \"Performing Grid Search of Naive Bayes classification\"\n",
    "# Range of parameters of the classification tuning\n",
    "param_dict_NB = {'feature_selection__k': range(5, len(features_list))}\n",
    "gs = grid_search(steps_NB, param_dict_NB, features, labels)\n",
    "gs_clf_NB = gs.best_estimator_\n",
    "print '\\n Score Metrics Decission Tree Classifier'\n",
    "test_classifier(gs_clf_NB, data_dict, features_list, folds = 1000)\n",
    "print\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "\n",
    "During this project, we have employed machine learning techniques to binary-classify ENRON employees into POI or non-POI. To do so, we have clean and analyzed financial related data. We have found that the Naive Bayes classifier is the one that better generalizes the data and, after parameter tuning, we have obtained accuracy, recall and precision bigger than 0.8 and 0.3 respectively. These results could be strongly improved with the inclusion of more POI data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bibliography\n",
    "\n",
    "* https://books.google.at/books/about/Introduction_to_Machine_Learning_with_Py.html?id=qjUVogEACAAJ&redir_esc=y\n",
    "* http://scikit-learn.org/stable/modules/outlier_detection.html\n",
    "* https://towardsdatascience.com/understanding-the-bias-variance-tradeoff-165e6942b229\n",
    "* https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6\n",
    "* https://machinelearningmastery.com/tactics-to-combat-imbalanced-classes-in-your-machine-learning-dataset/\n",
    "* http://scikit-learn.org/stable/modules/cross_validation.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
